# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 10834593135329314392), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 178712336188035793)]
# Vocab file /home/bcc/thcf16/tmp/iwslt15/vocab.de exists
# Vocab file /home/bcc/thcf16/tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_DE_s1000_l4_u32/hparams
  saving hparams to tmp/nmt_attention_model_DE_s1000_l4_u32/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_DE_s1000_l4_u32/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=/home/bcc/thcf16/tmp/iwslt15/newstest2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=4
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=4
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=1000
  num_translations_per_input=1
  num_units=32
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_DE_s1000_l4_u32
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=de
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=/home/bcc/thcf16/tmp/iwslt15/vocab.de
  src_vocab_size=50000
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=/home/bcc/thcf16/tmp/iwslt15/newstest2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=/home/bcc/thcf16/tmp/iwslt15/vocab.en
  tgt_vocab_size=50000
  time_major=True
  train_prefix=/home/bcc/thcf16/tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=/home/bcc/thcf16/tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=1000, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 50000), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 50000), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 50000), 
# log_file=tmp/nmt_attention_model_DE_s1000_l4_u32/log_1574820109
  created train model with fresh parameters, time 0.23s
  created infer model with fresh parameters, time 0.10s
  # 1421
    src: In ihrem ersten Fernsehinterview nach dem Attentat im Januar , bei dem sechs Menschen getötet und 13 verletzt wurden , lächelte Gifford , lachte und sang - und beschrieb ihre Genesung als &quot; schwierig &quot; .
    ref: In her first television interview since the January shooting that killed six and wounded 13 , Giffords smiled , laughed and sang - and described her recovery as &quot; difficult . &quot;
    nmt: fecha Sala Sala Sala Sala Sala Sala PLEASE tended tended tended liqueurs liqueurs liqueurs liqueurs liqueurs pizzerias pizzerias Ventilation Ventilation Schneider Schneider Schneider Schneider Schneider STC STC unfortunately unfortunately unfortunately email writable writable writable writable Ivanov Ivanov Ivanov Ivanov dissociate dissociate dissociate dissociate dissociate dissociate Frage asshole asshole asshole suicide suicide suicide suicide suicide suicide suicide suicide Waterford Waterford Waterford Waterford Waterford Waterford Waterford homeowners homeowners homeowners homeowners awaiting awaiting awaiting awaiting
  created eval model with fresh parameters, time 0.10s
  eval dev: perplexity 50002.20, time 29s, Tue Nov 26 23:02:19 2019.
  eval test: perplexity 50002.17, time 24s, Tue Nov 26 23:02:44 2019.
  created infer model with fresh parameters, time 0.08s
# Start step 0, lr 1, Tue Nov 26 23:02:44 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 1.90s wps 3.23K ppl 47894.54 gN 69.95 bleu 0.00, Tue Nov 26 23:05:54 2019
  step 200 lr 1 step-time 1.67s wps 3.63K ppl 5668.17 gN 25.95 bleu 0.00, Tue Nov 26 23:08:42 2019
  step 300 lr 1 step-time 1.68s wps 3.63K ppl 3536.84 gN 20.12 bleu 0.00, Tue Nov 26 23:11:30 2019
  step 400 lr 1 step-time 1.69s wps 3.64K ppl 2559.01 gN 15.60 bleu 0.00, Tue Nov 26 23:14:18 2019
  step 500 lr 1 step-time 1.66s wps 3.63K ppl 2345.42 gN 14.58 bleu 0.00, Tue Nov 26 23:17:04 2019
  step 600 lr 1 step-time 1.68s wps 3.62K ppl 2009.66 gN 12.74 bleu 0.00, Tue Nov 26 23:19:52 2019
  step 700 lr 1 step-time 1.69s wps 3.62K ppl 2008.36 gN 13.68 bleu 0.00, Tue Nov 26 23:22:41 2019
  step 800 lr 1 step-time 1.66s wps 3.63K ppl 1810.12 gN 12.19 bleu 0.00, Tue Nov 26 23:25:28 2019
  step 900 lr 1 step-time 1.68s wps 3.62K ppl 1821.82 gN 11.94 bleu 0.00, Tue Nov 26 23:28:16 2019
  step 1000 lr 1 step-time 1.68s wps 3.62K ppl 1595.96 gN 10.29 bleu 0.00, Tue Nov 26 23:31:04 2019
# Save eval, global step 1000
  loaded infer model parameters from tmp/nmt_attention_model_DE_s1000_l4_u32/translate.ckpt-1000, time 0.26s
  # 108
    src: Augenfällig war dies zum Beispiel bei den süßen Limos , wo viele Kinder begannen , gewöhnlichem Wasser den Vorrang zu geben .
    ref: This was quite significant , for example , in case of sweet soft drinks , where more children would begin to prefer plain water .
    nmt: <unk> <unk> <unk> <unk> <unk> <unk> and and and and and
  loaded eval model parameters from tmp/nmt_attention_model_DE_s1000_l4_u32/translate.ckpt-1000, time 0.05s
  eval dev: perplexity 3270.93, time 30s, Tue Nov 26 23:31:35 2019.
  eval test: perplexity 2773.59, time 24s, Tue Nov 26 23:32:00 2019.
  loaded infer model parameters from tmp/nmt_attention_model_DE_s1000_l4_u32/translate.ckpt-1000, time 0.25s
  # 2380
    src: Ein Großteil kam dem Räumungsbefehl nach und wechselte seinen Standort in einen nahe gelegenen Park .
    ref: A part of the protesters listened to the eviction order and moved to a nearby park .
    nmt: <unk> <unk> <unk> <unk> <unk> <unk> and and and and and
  loaded eval model parameters from tmp/nmt_attention_model_DE_s1000_l4_u32/translate.ckpt-1000, time 0.04s
  eval dev: perplexity 3270.93, time 30s, Tue Nov 26 23:32:31 2019.
  eval test: perplexity 2773.59, time 24s, Tue Nov 26 23:32:56 2019.
  loaded infer model parameters from tmp/nmt_attention_model_DE_s1000_l4_u32/translate.ckpt-1000, time 0.04s
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_DE_s1000_l4_u32/output_dev
  done, num sentences 3003, num translations per input 1, time 7s, Tue Nov 26 23:33:04 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_DE_s1000_l4_u32/hparams
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_DE_s1000_l4_u32/output_test
  done, num sentences 3000, num translations per input 1, time 7s, Tue Nov 26 23:33:12 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_DE_s1000_l4_u32/hparams
# Final, step 1000 lr 1 step-time 1.68s wps 3.62K ppl 1595.96 gN 10.29 dev ppl 3270.93, dev bleu 0.0, test ppl 2773.59, test bleu 0.0, Tue Nov 26 23:33:12 2019
# Done training!, time 1827s, Tue Nov 26 23:33:12 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.09s
  # 2273
    src: Wenn das Ziel von 500 bis 600 Untersuchungspersonen erreicht ist , wird die Studie auf dem Sportplatz von Independencia ( im Süden des Hauptstadtbezirks ) fortgesetzt und auf dem von Morelos ( im Norden des Hauptstadtbezirks ) abgeschlossen .
    ref: Once reached the goal of bringing 500 to 600 children , the study will continue in the Independence Sport Unit ( South the Mexico City ) and finally in the Morelos Sports Unit ( North the Mexico City ) .
    nmt: etwas reimbursed reimbursed reimbursed reimbursed Mayor reintroduction reintroduction reintroduction reintroduction reintroduction reintroduction reintroduction Moniz Moniz Moniz Moniz Moniz Moniz Moniz Oporto eurosceptic eurosceptic Depression Depression Depression Depression Depression Depression keepers keepers keepers keepers keepers Depression Depression Depression Depression Deals Deals Deals Deals Deals Deals Deals Fauna Fauna Fauna Fauna Libyans Libyans Libyans Libyans reintroduction nationalized nationalized nationalized nationalized nationalized nationalized Gard Roca Roca Roca Roca friendlier friendlier unfolded Profit Profit Profit Profit mat mat peu peu peu peu
  created eval model with fresh parameters, time 0.10s
  eval dev: perplexity 50002.11, time 30s, Tue Nov 26 23:33:43 2019.
  eval test: perplexity 50002.04, time 24s, Tue Nov 26 23:34:07 2019.
  created infer model with fresh parameters, time 0.09s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 1.68s wps 3.62K ppl 1595.96 gN 10.29 dev ppl 50002.11, dev bleu 0.0, test ppl 50002.04, test bleu 0.0, Tue Nov 26 23:34:08 2019
