# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 8592660194128812352), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14496708137823684084)]
# Vocab file tmp/iwslt15/vocab.vi exists
# Vocab file tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_VI_s100_l2_u128/hparams
  saving hparams to tmp/nmt_attention_model_VI_s100_l2_u128/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_VI_s100_l2_u128/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=tmp/iwslt15/tst2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=2
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=2
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=100
  num_translations_per_input=1
  num_units=128
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_VI_s100_l2_u128
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=vi
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=tmp/iwslt15/vocab.vi
  src_vocab_size=7709
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=tmp/iwslt15/tst2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=tmp/iwslt15/vocab.en
  tgt_vocab_size=17191
  time_major=True
  train_prefix=tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=100, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), 
# log_file=tmp/nmt_attention_model_VI_s100_l2_u128/log_1574881881
  created train model with fresh parameters, time 0.15s
  created infer model with fresh parameters, time 0.08s
  # 108
    src: Bởi vì chúng tôi là ai và cuộc đời đã định hình chúng tôi như thế nào , giờ chúng tôi có thể thấy rằng những người đàn ông mà có thể đã đi vào cuộc đời của chúng tôi sẽ ngăn trở chúng tôi .
    ref: Given who we were and how life had shaped us , we can now see that the men who might have come into our lives would have thwarted us .
    nmt: taxes taxes taxes taxes competitor accidental Water Water seafood filmed filmed filmed relational relational relational holidays sameness sameness plants plants plants plants Moskowitz Moskowitz sameness racism racism racism foreman racism racism points points gratitude points terrified points shredder shredder chance chance chance fading fading fading CSI emerging whistleblowers whistleblowers Bring Bring radio word word word word word geothermal geothermal geothermal multiplication multiplication old old old construct lightweight lightweight lightweight beep beep beep beep participating participating filtering filtering filtering filtering Jacobs Whewell Whewell Whewell Whewell Whewell serves serves serves serves starvation starvation seafood
  created eval model with fresh parameters, time 0.08s
  eval dev: perplexity 17193.95, time 5s, Wed Nov 27 16:11:27 2019.
  eval test: perplexity 17191.47, time 5s, Wed Nov 27 16:11:33 2019.
  created infer model with fresh parameters, time 0.07s
# Start step 0, lr 1, Wed Nov 27 16:11:33 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 0.99s wps 5.62K ppl 18355.58 gN 72.54 bleu 0.00, Wed Nov 27 16:13:12 2019
  loaded infer model parameters from tmp/nmt_attention_model_VI_s100_l2_u128/translate.ckpt-100, time 2.15s
  # 72
    src: Bức xếp hình cần một mảnh nữa .
    ref: There had to be another piece of the jigsaw .
    nmt: I I . . . . . . . . . . . . . .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s100_l2_u128/translate.ckpt-100, time 0.08s
  eval dev: perplexity 1191.27, time 5s, Wed Nov 27 16:13:22 2019.
  eval test: perplexity 1393.44, time 6s, Wed Nov 27 16:13:29 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s100_l2_u128/translate.ckpt-100, time 0.06s
# External evaluation, global step 100
  decoding to output tmp/nmt_attention_model_VI_s100_l2_u128/output_dev
  done, num sentences 1553, num translations per input 1, time 35s, Wed Nov 27 16:14:04 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s100_l2_u128/hparams
# External evaluation, global step 100
  decoding to output tmp/nmt_attention_model_VI_s100_l2_u128/output_test
  done, num sentences 1268, num translations per input 1, time 35s, Wed Nov 27 16:14:40 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s100_l2_u128/hparams
# Final, step 100 lr 1 step-time 0.99s wps 5.62K ppl 18355.58 gN 72.54 dev ppl 1191.27, dev bleu 0.0, test ppl 1393.44, test bleu 0.0, Wed Nov 27 16:14:41 2019
# Done training!, time 187s, Wed Nov 27 16:14:41 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.07s
  # 1455
    src: Như các bạn đã thấy , không chỉ đơn giản để chơi littleBits còn tỏ ra là một công cụ mạnh .
    ref: So beyond simple play , littleBits are actually pretty powerful .
    nmt: Kurdistan Kurdistan Kurdistan orders orders removing removing Speak Speak mixed mixed Speak Probably hip-hop hip-hop hip-hop removing removing Speak Speak biotech Jackson Jackson wandered yearning yearning yearning viewers Turns Turns Turns bites bites Violence Violence bottom-up modern-day modern-day modern-day modern-day modern-day took took Apollo
  created eval model with fresh parameters, time 0.08s
  eval dev: perplexity 17192.64, time 6s, Wed Nov 27 16:14:48 2019.
  eval test: perplexity 17191.75, time 6s, Wed Nov 27 16:14:54 2019.
  created infer model with fresh parameters, time 0.07s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 0.99s wps 5.62K ppl 18355.58 gN 72.54 dev ppl 17192.64, dev bleu 0.0, test ppl 17191.75, test bleu 0.0, Wed Nov 27 16:14:54 2019
