# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 17366359360002963088), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17937952968143142202)]
# Vocab file tmp/iwslt15/vocab.vi exists
# Vocab file tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_VI_s500_l2_u64/hparams
  saving hparams to tmp/nmt_attention_model_VI_s500_l2_u64/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_VI_s500_l2_u64/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=tmp/iwslt15/tst2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=2
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=2
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=500
  num_translations_per_input=1
  num_units=64
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_VI_s500_l2_u64
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=vi
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=tmp/iwslt15/vocab.vi
  src_vocab_size=7709
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=tmp/iwslt15/tst2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=tmp/iwslt15/vocab.en
  tgt_vocab_size=17191
  time_major=True
  train_prefix=tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=500, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), 
# log_file=tmp/nmt_attention_model_VI_s500_l2_u64/log_1574884166
  created train model with fresh parameters, time 0.15s
  created infer model with fresh parameters, time 0.08s
  # 928
    src: Và công ty nhỏ mới thành lập của tôi đang cố gắng thâm nhập vào môi trường bằng cách chú ý tới ...
    ref: And my small startup is looking to force ourselves into the environment by paying attention to ...
    nmt: Pentagon taxpayers taxpayers taxpayers immunized immunized transmit transmit contrast guitar guitar obsessed obsessed obsessed generous accepted accepted minds waterfront waterfront muffin AG AG Oscar Oscar rediscover rediscover vibrate vibrate blended blended blended 62 everybody everybody everybody forcing forcing dads dads suffer South transmit transmit ongoing ongoing
  created eval model with fresh parameters, time 0.07s
  eval dev: perplexity 17189.90, time 5s, Wed Nov 27 16:49:32 2019.
  eval test: perplexity 17189.93, time 5s, Wed Nov 27 16:49:37 2019.
  created infer model with fresh parameters, time 0.07s
# Start step 0, lr 1, Wed Nov 27 16:49:37 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 0.78s wps 7.07K ppl 13469.79 gN 52.43 bleu 0.00, Wed Nov 27 16:50:56 2019
  step 200 lr 1 step-time 0.72s wps 7.86K ppl 1060.92 gN 15.54 bleu 0.00, Wed Nov 27 16:52:07 2019
  step 300 lr 1 step-time 0.72s wps 7.88K ppl 559.35 gN 6.62 bleu 0.00, Wed Nov 27 16:53:19 2019
  step 400 lr 1 step-time 0.71s wps 7.89K ppl 465.23 gN 5.71 bleu 0.00, Wed Nov 27 16:54:30 2019
  step 500 lr 1 step-time 0.72s wps 7.86K ppl 377.69 gN 4.93 bleu 0.00, Wed Nov 27 16:55:42 2019
  loaded infer model parameters from tmp/nmt_attention_model_VI_s500_l2_u64/translate.ckpt-500, time 1.07s
  # 1363
    src: Nó có phải là nhiếp ảnh không nhỉ ?
    ref: Or is it photography ?
    nmt: And I <unk> the <unk> to <unk> .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s500_l2_u64/translate.ckpt-500, time 0.04s
  eval dev: perplexity 337.12, time 5s, Wed Nov 27 16:55:50 2019.
  eval test: perplexity 389.38, time 5s, Wed Nov 27 16:55:55 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s500_l2_u64/translate.ckpt-500, time 0.03s
# External evaluation, global step 500
  decoding to output tmp/nmt_attention_model_VI_s500_l2_u64/output_dev
  done, num sentences 1553, num translations per input 1, time 5s, Wed Nov 27 16:56:01 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s500_l2_u64/hparams
# External evaluation, global step 500
  decoding to output tmp/nmt_attention_model_VI_s500_l2_u64/output_test
  done, num sentences 1268, num translations per input 1, time 5s, Wed Nov 27 16:56:07 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s500_l2_u64/hparams
# Final, step 500 lr 1 step-time 0.72s wps 7.86K ppl 377.69 gN 4.93 dev ppl 337.12, dev bleu 0.0, test ppl 389.38, test bleu 0.0, Wed Nov 27 16:56:07 2019
# Done training!, time 389s, Wed Nov 27 16:56:07 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.07s
  # 386
    src: rằng tầm nhìn của tất cả chúng ta về công nghệ và những thiết kế , giải trí và sự sáng tạo hẳn phải luôn song hành cùng với tầm nhìn của cả cộng đồng , lòng trắc ẩn và công lý .
    ref: That our visions of technology and design and entertainment and creativity have to be married with visions of humanity , compassion and justice .
    nmt: hugged cloudy ambulance ambulance ambulance acute acute acute communal types types enforced enforced enforced enforced enforced enforced skulls skulls Stem skulls Uranus Uranus formula formula Drew enjoyable enjoyable enjoyable weaker defeating weaker memorizing memorizing nagging nagging West West West shift Bright Bright degrade degrade degrade degrade degrade degrade degrade pores pores pores pores pores pollination pollination underlies underlies underlies underlies McAfee McAfee McAfee portions portions evaluating evaluating evaluating actors actors actors intractable intractable intractable intractable intractable CC commit commit CC disrupted disrupted Bertie Bertie legal legal
  created eval model with fresh parameters, time 0.08s
  eval dev: perplexity 17190.73, time 5s, Wed Nov 27 16:56:13 2019.
  eval test: perplexity 17190.72, time 5s, Wed Nov 27 16:56:18 2019.
  created infer model with fresh parameters, time 0.07s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 0.72s wps 7.86K ppl 377.69 gN 4.93 dev ppl 17190.73, dev bleu 0.0, test ppl 17190.72, test bleu 0.0, Wed Nov 27 16:56:18 2019
