# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 10348140270072397012), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7749261808544005719)]
# Vocab file tmp/iwslt15/vocab.vi exists
# Vocab file tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/hparams
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_VI_s1000_l2_u64/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=tmp/iwslt15/tst2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=2
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=2
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=1000
  num_translations_per_input=1
  num_units=64
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_VI_s1000_l2_u64
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=vi
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=tmp/iwslt15/vocab.vi
  src_vocab_size=7709
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=tmp/iwslt15/tst2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=tmp/iwslt15/vocab.en
  tgt_vocab_size=17191
  time_major=True
  train_prefix=tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=1000, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 64), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 64), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (64, 64), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (192, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (128, 256), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (256,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (128, 64), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (64, 17191), 
# log_file=tmp/nmt_attention_model_VI_s1000_l2_u64/log_1574889370
  created train model with fresh parameters, time 0.14s
  created infer model with fresh parameters, time 0.07s
  # 153
    src: tôi nhớ như in ngày đó , tưởng chừng như mới xảy qua hôm qua vậy
    ref: And I remember this just like it happened yesterday .
    nmt: generosity Caucasus Caucasus Caucasus Caucasus photographs PowerPoint PowerPoint PowerPoint question Albert Albert Albert ever-increasing ever-increasing Buy Buy Buy livable Buy livable livable coverage Buy UC chip chip 3,000 3,000 Vancouver Vancouver plots
  created eval model with fresh parameters, time 0.06s
  eval dev: perplexity 17191.07, time 4s, Wed Nov 27 18:16:15 2019.
  eval test: perplexity 17190.84, time 4s, Wed Nov 27 18:16:20 2019.
  created infer model with fresh parameters, time 0.06s
# Start step 0, lr 1, Wed Nov 27 18:16:20 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 0.70s wps 7.91K ppl 27737.36 gN 73.44 bleu 0.00, Wed Nov 27 18:17:29 2019
  step 200 lr 1 step-time 0.65s wps 8.79K ppl 815.22 gN 11.33 bleu 0.00, Wed Nov 27 18:18:34 2019
  step 300 lr 1 step-time 0.63s wps 8.78K ppl 523.03 gN 6.88 bleu 0.00, Wed Nov 27 18:19:37 2019
  step 400 lr 1 step-time 0.65s wps 8.75K ppl 433.69 gN 6.08 bleu 0.00, Wed Nov 27 18:20:42 2019
  step 500 lr 1 step-time 0.64s wps 8.74K ppl 346.66 gN 4.99 bleu 0.00, Wed Nov 27 18:21:46 2019
  step 600 lr 1 step-time 0.64s wps 8.78K ppl 301.57 gN 5.10 bleu 0.00, Wed Nov 27 18:22:50 2019
  step 700 lr 1 step-time 0.65s wps 8.79K ppl 255.04 gN 4.53 bleu 0.00, Wed Nov 27 18:23:55 2019
  step 800 lr 1 step-time 0.64s wps 8.70K ppl 232.05 gN 4.47 bleu 0.00, Wed Nov 27 18:24:59 2019
  step 900 lr 1 step-time 0.65s wps 8.76K ppl 217.78 gN 4.16 bleu 0.00, Wed Nov 27 18:26:03 2019
  step 1000 lr 1 step-time 0.64s wps 8.74K ppl 204.50 gN 4.22 bleu 0.00, Wed Nov 27 18:27:07 2019
# Save eval, global step 1000
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/translate.ckpt-1000, time 1.07s
  # 300
    src: tôi nói &quot; Tôi sẽ lắng nghe &quot;
    ref: I said , &quot; I &apos;m going to listen . &quot;
    nmt: And I was a lot of the <unk> , I was a lot of the <unk>
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/translate.ckpt-1000, time 0.04s
  eval dev: perplexity 146.36, time 4s, Wed Nov 27 18:27:15 2019.
  eval test: perplexity 164.35, time 4s, Wed Nov 27 18:27:19 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/translate.ckpt-1000, time 1.06s
  # 1419
    src: Và đây , các phần được sắp xếp rất ổn .
    ref: And here every piece is very well planned .
    nmt: And I was a lot of the <unk> , and I was a lot of the <unk> , and I was a
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/translate.ckpt-1000, time 0.03s
  eval dev: perplexity 146.36, time 4s, Wed Nov 27 18:27:26 2019.
  eval test: perplexity 164.35, time 4s, Wed Nov 27 18:27:31 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/translate.ckpt-1000, time 0.03s
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l2_u64/output_dev
  done, num sentences 1553, num translations per input 1, time 17s, Wed Nov 27 18:27:48 2019.
  bleu dev: 0.1
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/hparams
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l2_u64/output_test
  done, num sentences 1268, num translations per input 1, time 16s, Wed Nov 27 18:28:06 2019.
  bleu test: 0.2
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/hparams
# Final, step 1000 lr 1 step-time 0.64s wps 8.74K ppl 204.50 gN 4.22 dev ppl 146.36, dev bleu 0.1, test ppl 164.35, test bleu 0.2, Wed Nov 27 18:28:07 2019
# Done training!, time 707s, Wed Nov 27 18:28:07 2019.
# Start evaluating saved best models.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/best_bleu/translate.ckpt-1000, time 1.05s
  # 1186
    src: Chúng tôi lựa chọn một vài ứng viên mỗi năm , họ sẽ làm việc với chính quyền thành phố .
    ref: We select a few fellows every year and we have them work with city governments .
    nmt: But I was a lot of the <unk> , and I was a lot of the <unk> , and I was a lot of the <unk> , and I was a lot of the <unk> , and I was a lot of
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/best_bleu/translate.ckpt-1000, time 0.03s
  eval dev: perplexity 146.36, time 4s, Wed Nov 27 18:28:13 2019.
  eval test: perplexity 164.35, time 4s, Wed Nov 27 18:28:17 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l2_u64/best_bleu/translate.ckpt-1000, time 0.03s
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l2_u64/output_dev
  done, num sentences 1553, num translations per input 1, time 17s, Wed Nov 27 18:28:35 2019.
  bleu dev: 0.1
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/hparams
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l2_u64/output_test
  done, num sentences 1268, num translations per input 1, time 16s, Wed Nov 27 18:28:52 2019.
  bleu test: 0.2
  saving hparams to tmp/nmt_attention_model_VI_s1000_l2_u64/hparams
# Best bleu, step 1000 lr 1 step-time 0.64s wps 8.74K ppl 204.50 gN 4.22 dev ppl 146.36, dev bleu 0.1, test ppl 164.35, test bleu 0.2, Wed Nov 27 18:28:52 2019
