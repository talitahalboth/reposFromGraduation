# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 1487167901159919365), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7943540578853076273)]
# Vocab file /home/bcc/thcf16/tmp/iwslt15/vocab.de exists
# Vocab file /home/bcc/thcf16/tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_DE_s500_l2_u256/hparams
  saving hparams to tmp/nmt_attention_model_DE_s500_l2_u256/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_DE_s500_l2_u256/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=/home/bcc/thcf16/tmp/iwslt15/newstest2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=2
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=2
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=500
  num_translations_per_input=1
  num_units=256
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_DE_s500_l2_u256
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=de
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=/home/bcc/thcf16/tmp/iwslt15/vocab.de
  src_vocab_size=50000
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=/home/bcc/thcf16/tmp/iwslt15/newstest2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=/home/bcc/thcf16/tmp/iwslt15/vocab.en
  tgt_vocab_size=50000
  time_major=True
  train_prefix=/home/bcc/thcf16/tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=/home/bcc/thcf16/tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=500, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 256), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (256, 256), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (768, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (512, 256), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 50000), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 256), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (256, 256), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (768, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (512, 256), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 50000), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 2, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (50000, 256), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (50000, 256), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (256, 256), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (768, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (512, 1024), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (1024,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (512, 256), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 50000), 
# log_file=tmp/nmt_attention_model_DE_s500_l2_u256/log_1574798915
  created train model with fresh parameters, time 0.24s
  created infer model with fresh parameters, time 0.16s
  # 504
    src: Seither fliegen alljährlich direkte Charter ##AT##-##AT## Flugzeuge mit tschechischen Passagieren in weit entfernte sonnige Länder ; in diesem Jahr fliegt man direkt aus Tschechien zwölf exotische Destinationen an .
    ref: Since then , direct charter flights take Czech tourists to warm exotic countries . This winter , flights from the Czech Republic will reach twelve exotic destinations .
    nmt: &apos;Ger Luck Luck Luck Prets Prets Prets Prets Prets Prets Prets virtualized virtualized virtualized virtualized contravene contravene contravene hostile hostile hostile hostile hostile skype Kemal Kemal Kemal Kemal Reformation Reformation raison raison Plooij Plooij Plooij Plooij Plooij pesticides pesticides pesticides pesticides pesticides pesticides pesticides pesticides nots nots PR PR PR PR PR PR PR tuning tuning tuning tuning
  created eval model with fresh parameters, time 0.17s
  eval dev: perplexity 50182.36, time 46s, Tue Nov 26 17:09:23 2019.
  eval test: perplexity 50119.15, time 38s, Tue Nov 26 17:10:01 2019.
  created infer model with fresh parameters, time 0.18s
# Start step 0, lr 1, Tue Nov 26 17:10:01 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 3.86s wps 1.57K ppl 133169.01 gN 48956.98 bleu 0.00, Tue Nov 26 17:16:28 2019
  step 200 lr 1 step-time 3.64s wps 1.67K ppl 9130.02 gN 79.38 bleu 0.00, Tue Nov 26 17:22:31 2019
  step 300 lr 1 step-time 3.65s wps 1.67K ppl 2343.81 gN 18.91 bleu 0.00, Tue Nov 26 17:28:36 2019
  step 400 lr 1 step-time 3.67s wps 1.67K ppl 1649.84 gN 19.47 bleu 0.00, Tue Nov 26 17:34:43 2019
  step 500 lr 1 step-time 3.65s wps 1.66K ppl 1227.15 gN 8.89 bleu 0.00, Tue Nov 26 17:40:49 2019
  loaded infer model parameters from tmp/nmt_attention_model_DE_s500_l2_u256/translate.ckpt-500, time 1.61s
  # 1770
    src: &quot; Es ist ein Luftwaffengeschwader ohne ausreichend geschulte Piloten . &quot;
    ref: &quot; It &apos;s an air wing without enough trained pilots . &quot;
    nmt: The the the the the the the the the the the the the the the the the the the the the the
  loaded eval model parameters from tmp/nmt_attention_model_DE_s500_l2_u256/translate.ckpt-500, time 0.16s
  eval dev: perplexity 1178.54, time 44s, Tue Nov 26 17:41:38 2019.
  eval test: perplexity 1034.13, time 38s, Tue Nov 26 17:42:17 2019.
  loaded infer model parameters from tmp/nmt_attention_model_DE_s500_l2_u256/translate.ckpt-500, time 0.13s
# External evaluation, global step 500
  decoding to output tmp/nmt_attention_model_DE_s500_l2_u256/output_dev
  done, num sentences 3003, num translations per input 1, time 221s, Tue Nov 26 17:45:58 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_DE_s500_l2_u256/hparams
# External evaluation, global step 500
  decoding to output tmp/nmt_attention_model_DE_s500_l2_u256/output_test
  done, num sentences 3000, num translations per input 1, time 202s, Tue Nov 26 17:49:22 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_DE_s500_l2_u256/hparams
# Final, step 500 lr 1 step-time 3.65s wps 1.66K ppl 1227.15 gN 8.89 dev ppl 1178.54, dev bleu 0.0, test ppl 1034.13, test bleu 0.0, Tue Nov 26 17:49:22 2019
# Done training!, time 2361s, Tue Nov 26 17:49:22 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.18s
  # 1165
    src: Er kam mit Gesichts- und Beinverletzungen in ein Krankenhaus , wie die Polizei am Montag mitteilte .
    ref: The police announced in a statement that he was taken to hospital with injuries to the face and leg .
    nmt: deceitful obligated ATA ATA Magdalena publishers publishers revulsion Eligible Eligible Eligible cock Roaming Roaming Roaming Defining Defining inherently inherently Riverside Riverside Riverside Riverside Riverside weaves weaves entailing entailing entailing entailing entailing February February February
  created eval model with fresh parameters, time 0.19s
  eval dev: perplexity 49729.95, time 46s, Tue Nov 26 17:50:09 2019.
  eval test: perplexity 49799.84, time 38s, Tue Nov 26 17:50:48 2019.
  created infer model with fresh parameters, time 0.18s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 3.65s wps 1.66K ppl 1227.15 gN 8.89 dev ppl 49729.95, dev bleu 0.0, test ppl 49799.84, test bleu 0.0, Tue Nov 26 17:50:50 2019
