# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 11064246336507720293), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 889225223856258628)]
# Vocab file tmp/iwslt15/vocab.vi exists
# Vocab file tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u32/hparams
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u32/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_VI_s1000_l4_u32/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=tmp/iwslt15/tst2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=4
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=4
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=1000
  num_translations_per_input=1
  num_units=32
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_VI_s1000_l4_u32
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=vi
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=tmp/iwslt15/vocab.vi
  src_vocab_size=7709
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=tmp/iwslt15/tst2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=tmp/iwslt15/vocab.en
  tgt_vocab_size=17191
  time_major=True
  train_prefix=tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=1000, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 17191), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 17191), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 32), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 32), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (32, 32), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (96, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (64, 128), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (128,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (64, 32), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (32, 17191), 
# log_file=tmp/nmt_attention_model_VI_s1000_l4_u32/log_1574893036
  created train model with fresh parameters, time 0.20s
  created infer model with fresh parameters, time 0.08s
  # 232
    src: cứ 9 người bị kết án tử chúng tôi tìm thấy một người vô tội được giải tội và thả khỏi tử tù
    ref: For every nine people who have been executed , we &apos;ve actually identified one innocent person who &apos;s been exonerated and released from death row .
    nmt: O2 wiring bankers forge forge L L L Zipcar Zipcar solution solution zooming zooming zooming zooming zooming zooming fishing Maidan Maidan Maidan Maidan Maidan commands commands commands commands commands Leonard Leonard Leonard Leonard expo expo expo cooler cooler cooler prevent prevent prevent prevent prevent inert inert
  created eval model with fresh parameters, time 0.08s
  eval dev: perplexity 17191.48, time 4s, Wed Nov 27 19:17:22 2019.
  eval test: perplexity 17191.01, time 4s, Wed Nov 27 19:17:27 2019.
  created infer model with fresh parameters, time 0.07s
# Start step 0, lr 1, Wed Nov 27 19:17:27 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 0.64s wps 8.60K ppl 14264.67 gN 46.19 bleu 0.00, Wed Nov 27 19:18:31 2019
  step 200 lr 1 step-time 0.58s wps 9.71K ppl 1267.64 gN 14.88 bleu 0.00, Wed Nov 27 19:19:29 2019
  step 300 lr 1 step-time 0.58s wps 9.76K ppl 735.71 gN 8.27 bleu 0.00, Wed Nov 27 19:20:27 2019
  step 400 lr 1 step-time 0.57s wps 9.68K ppl 560.53 gN 6.75 bleu 0.00, Wed Nov 27 19:21:24 2019
  step 500 lr 1 step-time 0.58s wps 9.74K ppl 497.12 gN 6.22 bleu 0.00, Wed Nov 27 19:22:22 2019
  step 600 lr 1 step-time 0.58s wps 9.72K ppl 437.90 gN 4.97 bleu 0.00, Wed Nov 27 19:23:20 2019
  step 700 lr 1 step-time 0.58s wps 9.71K ppl 402.68 gN 4.72 bleu 0.00, Wed Nov 27 19:24:19 2019
  step 800 lr 1 step-time 0.58s wps 9.80K ppl 357.63 gN 4.12 bleu 0.00, Wed Nov 27 19:25:16 2019
  step 900 lr 1 step-time 0.58s wps 9.70K ppl 337.94 gN 3.99 bleu 0.00, Wed Nov 27 19:26:15 2019
  step 1000 lr 1 step-time 0.57s wps 9.64K ppl 310.75 gN 3.64 bleu 0.00, Wed Nov 27 19:27:12 2019
# Save eval, global step 1000
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u32/translate.ckpt-1000, time 0.56s
  # 385
    src: Rằng sự tồn tại của tất cả chúng ta gắn bó mật thiết với sự tồn tài của từng người .
    ref: That all of our survival is tied to the survival of everyone .
    nmt: And I know , the <unk> , the <unk> , the <unk> .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l4_u32/translate.ckpt-1000, time 0.04s
  eval dev: perplexity 216.16, time 4s, Wed Nov 27 19:27:18 2019.
  eval test: perplexity 243.84, time 4s, Wed Nov 27 19:27:23 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u32/translate.ckpt-1000, time 0.55s
  # 1252
    src: Boston không chỉ có một tổng đài .
    ref: Boston doesn &apos;t just have a call center .
    nmt: It &apos;s the <unk> , the <unk> .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l4_u32/translate.ckpt-1000, time 0.03s
  eval dev: perplexity 216.16, time 4s, Wed Nov 27 19:27:29 2019.
  eval test: perplexity 243.84, time 4s, Wed Nov 27 19:27:33 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u32/translate.ckpt-1000, time 0.03s
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l4_u32/output_dev
  done, num sentences 1553, num translations per input 1, time 4s, Wed Nov 27 19:27:38 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u32/hparams
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l4_u32/output_test
  done, num sentences 1268, num translations per input 1, time 3s, Wed Nov 27 19:27:41 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u32/hparams
# Final, step 1000 lr 1 step-time 0.57s wps 9.64K ppl 310.75 gN 3.64 dev ppl 216.16, dev bleu 0.0, test ppl 243.84, test bleu 0.0, Wed Nov 27 19:27:42 2019
# Done training!, time 614s, Wed Nov 27 19:27:42 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.08s
  # 301
    src: Và rồi tôi đến đó , và tôi sẽ chỉ lắng nghe
    ref: And I &apos;d go over there and I would , I would just listen .
    nmt: prerequisite prerequisite box Worldchanging Worldchanging Worldchanging message Doing Doing Mother Mother Mother Mother Mother Mother magically magically master master laying laying laying highest conflicts
  created eval model with fresh parameters, time 0.08s
  eval dev: perplexity 17191.42, time 4s, Wed Nov 27 19:27:46 2019.
  eval test: perplexity 17190.95, time 4s, Wed Nov 27 19:27:51 2019.
  created infer model with fresh parameters, time 0.08s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 0.57s wps 9.64K ppl 310.75 gN 3.64 dev ppl 17191.42, dev bleu 0.0, test ppl 17190.95, test bleu 0.0, Wed Nov 27 19:27:51 2019
