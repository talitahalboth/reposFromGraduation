# Job id 0
# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 4047988436448308983), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13289927376645610602)]
# Vocab file tmp/iwslt15/vocab.vi exists
# Vocab file tmp/iwslt15/vocab.en exists
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u128/hparams
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u128/best_bleu/hparams
  attention=scaled_luong
  attention_architecture=standard
  avg_ckpts=False
  batch_size=128
  beam_width=0
  best_bleu=0
  best_bleu_dir=tmp/nmt_attention_model_VI_s1000_l4_u128/best_bleu
  check_special_token=True
  colocate_gradients_with_ops=True
  coverage_penalty_weight=0.0
  decay_scheme=
  dev_prefix=tmp/iwslt15/tst2012
  dropout=0.2
  embed_prefix=None
  encoder_type=uni
  eos=</s>
  epoch_step=0
  forget_bias=1.0
  infer_batch_size=32
  infer_mode=greedy
  init_op=uniform
  init_weight=0.1
  language_model=False
  learning_rate=1.0
  length_penalty_weight=0.0
  log_device_placement=False
  max_gradient_norm=5.0
  max_train=0
  metrics=['bleu']
  num_buckets=5
  num_dec_emb_partitions=0
  num_decoder_layers=4
  num_decoder_residual_layers=0
  num_embeddings_partitions=0
  num_enc_emb_partitions=0
  num_encoder_layers=4
  num_encoder_residual_layers=0
  num_gpus=1
  num_inter_threads=0
  num_intra_threads=0
  num_keep_ckpts=5
  num_sampled_softmax=0
  num_train_steps=1000
  num_translations_per_input=1
  num_units=128
  optimizer=sgd
  out_dir=tmp/nmt_attention_model_VI_s1000_l4_u128
  output_attention=True
  override_loaded_hparams=False
  pass_hidden_state=True
  random_seed=None
  residual=False
  sampling_temperature=0.0
  share_vocab=False
  sos=<s>
  src=vi
  src_embed_file=
  src_max_len=50
  src_max_len_infer=None
  src_vocab_file=tmp/iwslt15/vocab.vi
  src_vocab_size=7709
  steps_per_external_eval=None
  steps_per_stats=100
  subword_option=
  test_prefix=tmp/iwslt15/tst2013
  tgt=en
  tgt_embed_file=
  tgt_max_len=50
  tgt_max_len_infer=None
  tgt_vocab_file=tmp/iwslt15/vocab.en
  tgt_vocab_size=17191
  time_major=True
  train_prefix=tmp/iwslt15/train
  unit_type=lstm
  use_char_encode=False
  vocab_prefix=tmp/iwslt15/vocab
  warmup_scheme=t2t
  warmup_steps=0
# Creating train graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0
  learning_rate=1, warmup_steps=0, warmup_scheme=t2t
  decay_scheme=, start_decay_step=1000, decay_steps 0, decay_factor 1
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0
# Creating eval graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0
# Creating infer graph ...
# Build a basic encoder
  num_layers = 4, num_residual_layers=0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 2  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  cell 3  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0
  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000
# Trainable variables
Format: <name>, <shape>, <(soft) device placement>
  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0
  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), 
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0
  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (512,), /device:GPU:0
  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0
  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0
  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), 
# log_file=tmp/nmt_attention_model_VI_s1000_l4_u128/log_1574894482
  created train model with fresh parameters, time 0.22s
  created infer model with fresh parameters, time 0.09s
  # 283
    src: Vâng . Chúng ta có lý , chúng ta cống hiến cho trí tuệ .
    ref: We do . As rational as we are , as committed to intellect as we are .
    nmt: urgency consume consume MW MW MW MW MW inundated inundated inundated inundated inundated inundated ark ark mindful mindful mindful fraction fraction fraction fraction sermons sermons sermons sermons tail disturbed disturbed
  created eval model with fresh parameters, time 0.09s
  eval dev: perplexity 17191.54, time 6s, Wed Nov 27 19:41:29 2019.
  eval test: perplexity 17191.39, time 6s, Wed Nov 27 19:41:35 2019.
  created infer model with fresh parameters, time 0.09s
# Start step 0, lr 1, Wed Nov 27 19:41:36 2019
# Init train iterator, skipping 0 elements
  step 100 lr 1 step-time 1.11s wps 5.03K ppl 30815.97 gN 73.19 bleu 0.00, Wed Nov 27 19:43:27 2019
  step 200 lr 1 step-time 1.04s wps 5.37K ppl 2375.07 gN 26.38 bleu 0.00, Wed Nov 27 19:45:11 2019
  step 300 lr 1 step-time 1.05s wps 5.38K ppl 1121.97 gN 15.04 bleu 0.00, Wed Nov 27 19:46:56 2019
  step 400 lr 1 step-time 1.06s wps 5.35K ppl 1121.55 gN 21.19 bleu 0.00, Wed Nov 27 19:48:42 2019
  step 500 lr 1 step-time 1.04s wps 5.35K ppl 736.12 gN 8.71 bleu 0.00, Wed Nov 27 19:50:27 2019
  step 600 lr 1 step-time 1.04s wps 5.35K ppl 625.13 gN 6.40 bleu 0.00, Wed Nov 27 19:52:11 2019
  step 700 lr 1 step-time 1.04s wps 5.37K ppl 541.56 gN 6.06 bleu 0.00, Wed Nov 27 19:53:55 2019
  step 800 lr 1 step-time 1.07s wps 5.36K ppl 443.75 gN 4.69 bleu 0.00, Wed Nov 27 19:55:42 2019
  step 900 lr 1 step-time 1.03s wps 5.33K ppl 394.80 gN 4.35 bleu 0.00, Wed Nov 27 19:57:25 2019
  step 1000 lr 1 step-time 1.06s wps 5.35K ppl 363.84 gN 4.30 bleu 0.00, Wed Nov 27 19:59:11 2019
# Save eval, global step 1000
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u128/translate.ckpt-1000, time 2.33s
  # 83
    src: Hầu hết ý tưởng của chúng tôi đều điên khùng , nhưng vài ý tưởng vô cùng tuyệt vời , và chúng tôi tạo ra đột phá .
    ref: Most of our ideas were crazy , but a few were brilliant , and we broke through .
    nmt: And I &apos;re <unk> .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l4_u128/translate.ckpt-1000, time 0.05s
  eval dev: perplexity 326.72, time 6s, Wed Nov 27 19:59:23 2019.
  eval test: perplexity 398.97, time 6s, Wed Nov 27 19:59:29 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u128/translate.ckpt-1000, time 2.34s
  # 851
    src: Tôi vẫn không biết các bạn nghĩ gì về tôi , nhưng tôi có thể chịu được điều đó .
    ref: I still don &apos;t know what you think of me , but I can live with that .
    nmt: And I &apos;re <unk> .
  loaded eval model parameters from tmp/nmt_attention_model_VI_s1000_l4_u128/translate.ckpt-1000, time 0.05s
  eval dev: perplexity 326.72, time 6s, Wed Nov 27 19:59:41 2019.
  eval test: perplexity 398.97, time 6s, Wed Nov 27 19:59:47 2019.
  loaded infer model parameters from tmp/nmt_attention_model_VI_s1000_l4_u128/translate.ckpt-1000, time 0.04s
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l4_u128/output_dev
  done, num sentences 1553, num translations per input 1, time 8s, Wed Nov 27 19:59:55 2019.
  bleu dev: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u128/hparams
# External evaluation, global step 1000
  decoding to output tmp/nmt_attention_model_VI_s1000_l4_u128/output_test
  done, num sentences 1268, num translations per input 1, time 9s, Wed Nov 27 20:00:05 2019.
  bleu test: 0.0
  saving hparams to tmp/nmt_attention_model_VI_s1000_l4_u128/hparams
# Final, step 1000 lr 1 step-time 1.06s wps 5.35K ppl 363.84 gN 4.30 dev ppl 326.72, dev bleu 0.0, test ppl 398.97, test bleu 0.0, Wed Nov 27 20:00:05 2019
# Done training!, time 1109s, Wed Nov 27 20:00:05 2019.
# Start evaluating saved best models.
  created infer model with fresh parameters, time 0.09s
  # 345
    src: và vì tôi thức quá khuya , mà không suy nghĩ một cách hệ thống Thế là tôi bắt đầu viết ra một bản kiến nghị
    ref: And because I was up too late , wasn &apos;t thinking real straight , I started working on a motion .
    nmt: fails coat coat aliens aliens string string string string Jonas Jonas Jonas Jonas chased chased repeated repeated repeated repeated repeated repeated repeated worrisome worrisome worrisome worrisome worrisome worrisome compromising compromising compromising overlook overlook overlook overlook overlook overlook cascade iPhones revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary revolutionary board distress
  created eval model with fresh parameters, time 0.10s
  eval dev: perplexity 17191.43, time 6s, Wed Nov 27 20:00:12 2019.
  eval test: perplexity 17191.61, time 6s, Wed Nov 27 20:00:18 2019.
  created infer model with fresh parameters, time 0.09s
  bleu dev: 0.0
  bleu test: 0.0
# Best bleu, step 0 lr 1 step-time 1.06s wps 5.35K ppl 363.84 gN 4.30 dev ppl 17191.43, dev bleu 0.0, test ppl 17191.61, test bleu 0.0, Wed Nov 27 20:00:19 2019
