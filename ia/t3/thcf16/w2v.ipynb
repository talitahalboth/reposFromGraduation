{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import nltk\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import statistics \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('datasets/imdb.csv')\n",
    "dataset.head()\n",
    "dataset = dataset[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removeMostUsed tells if words used more than the provided percentage should be removed.\n",
    "# if false, words used less then the percentage should be removed\n",
    "def removeWords(tmpDataSet, removeMostUsed=True, percentage=0.5):\n",
    "    numberEntries = len(tmpDataSet)\n",
    "    neededAmount = numberEntries * percentage\n",
    "    \n",
    "    removeWords = {}\n",
    "    for text in tmpDataSet:\n",
    "        thisremoveWords = {}\n",
    "        for word in text:\n",
    "            if (word not in thisremoveWords):\n",
    "                thisremoveWords[word]=1\n",
    "                if (word not in removeWords):\n",
    "                    removeWords[word]=1\n",
    "                else:\n",
    "                    removeWords[word]+=1\n",
    "    # accedp only words used the needed amount or less\n",
    "    if (removeMostUsed == True):\n",
    "        removeWords = dict((k, v) for k, v in removeWords.items() if v >= neededAmount)\n",
    "    # accedp only words used the needed amount or more\n",
    "    else:\n",
    "        removeWords = dict((k, v) for k, v in removeWords.items() if v <= neededAmount)\n",
    "    newtmpDataSet = []\n",
    "    for text in tmpDataSet:\n",
    "        cleaned_list = [word for word in text if word not in removeWords]\n",
    "        newtmpDataSet.append(cleaned_list)\n",
    "\n",
    "    return (newtmpDataSet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMultipleTimes(dataset):\n",
    "    f = open(\"w2v.txt\", \"w\")\n",
    "    percentageAndMostused = [[True, 1.0], [True, .9], [True, .8], [True, .7], [False, .3], [False, .2], [False, .1]]\n",
    "\n",
    "    avgScores = []\n",
    "    allScores = []\n",
    "    sdScores = []\n",
    "    avgF1Scores = []\n",
    "    sdF1Scoress = []\n",
    "    allF1Scores = []\n",
    "    allLoss = []\n",
    "    for elem in percentageAndMostused:\n",
    "        X = [sent for sent in dataset['review']]\n",
    "        X = [simple_preprocess(sent, deacc=True) for sent in X]\n",
    "        X1 = removeWords(X, removeMostUsed=elem[0], percentage=elem[1])\n",
    "\n",
    "        model = Word2Vec(X1, min_count=1, size=300, window=10)\n",
    "       \n",
    "        avgScore = 0\n",
    "        avgF1Score = 0\n",
    "        count = 30\n",
    "        scores = []\n",
    "        f1scores = []\n",
    "        loss = []\n",
    "        print(elem)\n",
    "        for x in range(count):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X1, dataset['sentiment'], test_size=0.33)\n",
    "            \n",
    "            (model.train(X1, total_examples=len(X), epochs=30))\n",
    "            X_train_v = []\n",
    "            for sent in X_train:\n",
    "                sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "                X_train_v.append(sent_vector)                \n",
    "            X_test_v = []\n",
    "            for sent in X_test:\n",
    "                sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "                X_test_v.append(sent_vector)\n",
    "            mlp = MLPClassifier(max_iter=300)\n",
    "            (mlp.fit(X_train_v, y_train))\n",
    "            scores.append(mlp.score(X_test_v, y_test))\n",
    "            y_pred = mlp.predict(X_test_v)\n",
    "            f1scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "            loss.append(mlp.loss_)\n",
    "\n",
    "        avgScore = statistics.mean(scores)\n",
    "        allScores.append(scores)\n",
    "        avgF1Score = statistics.mean(f1scores)\n",
    "        allF1Scores.append(f1scores)\n",
    "\n",
    "        sdScore = statistics.stdev(scores)\n",
    "        sdF1Score = statistics.stdev(scores)\n",
    "\n",
    "        avgScores.append(avgScore)\n",
    "        avgF1Scores.append(avgF1Score)\n",
    "        sdScores.append(sdScore)\n",
    "        sdF1Scoress.append(sdF1Score)\n",
    "\n",
    "        allLoss.append(loss)\n",
    "        avgLoss = statistics.mean(loss)\n",
    "        sdLoss = statistics.stdev(loss)\n",
    "        print(avgScore,avgF1Score,avgLoss)\n",
    "\n",
    "\n",
    "        f.write(\"most used: \" + str(elem[0]) + '\\n')\n",
    "        f.write(\"rate \" + str(elem[1]) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average Score \" + str(avgScore) + '\\n')\n",
    "        f.write(\"Score sd \" + str(sdScore) + '\\n')\n",
    "        f.write(\"All Scores\" + str(scores) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average Loss \" + str(avgLoss) + '\\n')\n",
    "        f.write(\"Loss sd \" + str(sdLoss) + '\\n')\n",
    "        f.write(\"All losses\" + str(loss) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average F1Score \" + str(avgF1Score) + '\\n')\n",
    "        f.write(\"F1Score sd \" + str(sdF1Score) + '\\n')\n",
    "        f.write(\"All F1 Scores\" + str(f1scores) + '\\n\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runWindowAndMinCount(dataset):\n",
    "    f = open(\"w2v.txt\", \"w\")\n",
    "    scoresF = open(\"pvalues/w2vWindowMinCount/scores.txt\", \"w\")\n",
    "    f1scoresF = open(\"pvalues/w2vWindowMinCount/f1Scores.txt\", \"w\")\n",
    "    lossF = open(\"pvalues/w2vWindowMinCount/loss.txt\", \"w\")\n",
    "\n",
    "    minCountAndWindow = []\n",
    "    for minCount in range (1, 6):\n",
    "        for window in range (5, 11):\n",
    "            minCountAndWindow.append([minCount, window])\n",
    "\n",
    "    avgScores = []\n",
    "    allScores = []\n",
    "    sdScores = []\n",
    "    avgF1Scores = []\n",
    "    sdF1Scoress = []\n",
    "    allF1Scores = []\n",
    "    allLoss = []\n",
    "    X = [remove_stopwords(sent)  for sent in dataset['review']]\n",
    "    X = [simple_preprocess(sent, deacc=True) for sent in X]\n",
    "    for elem in minCountAndWindow:\n",
    "\n",
    "        model = Word2Vec(X, min_count=elem[0], size=300, window=elem[1])\n",
    "       \n",
    "        avgScore = 0\n",
    "        avgF1Score = 0\n",
    "        count = 30\n",
    "        scores = []\n",
    "        f1scores = []\n",
    "        loss = []\n",
    "        print(elem)\n",
    "        for x in range(count):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, dataset['sentiment'], test_size=0.33)\n",
    "            \n",
    "            (model.train(X, total_examples=len(X), epochs=30))\n",
    "            X_train_v = []\n",
    "            for sent in X_train:\n",
    "                sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "                X_train_v.append(sent_vector)                \n",
    "            X_test_v = []\n",
    "            for sent in X_test:\n",
    "                sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "                X_test_v.append(sent_vector)\n",
    "            mlp = MLPClassifier(max_iter=300)\n",
    "            (mlp.fit(X_train_v, y_train))\n",
    "            scores.append(mlp.score(X_test_v, y_test))\n",
    "            y_pred = mlp.predict(X_test_v)\n",
    "            f1scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "            loss.append(mlp.loss_)\n",
    "\n",
    "        avgScore = statistics.mean(scores)\n",
    "        allScores.append(scores)\n",
    "        avgF1Score = statistics.mean(f1scores)\n",
    "        allF1Scores.append(f1scores)\n",
    "\n",
    "        sdScore = statistics.stdev(scores)\n",
    "        sdF1Score = statistics.stdev(scores)\n",
    "\n",
    "        avgScores.append(avgScore)\n",
    "        avgF1Scores.append(avgF1Score)\n",
    "        sdScores.append(sdScore)\n",
    "        sdF1Scoress.append(sdF1Score)\n",
    "\n",
    "        allLoss.append(loss)\n",
    "        avgLoss = statistics.mean(loss)\n",
    "        sdLoss = statistics.stdev(loss)\n",
    "\n",
    "        scoresF.write(str(scores)+'\\n')\n",
    "        lossF.write(str(loss)+'\\n')\n",
    "        f1scoresF.write(str(f1scores)+'\\n')\n",
    "\n",
    "        f.write(\"min_count: \" + str(elem[0]) + '\\n')\n",
    "        f.write(\"window: \" + str(elem[1]) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average Score \" + str(avgScore) + '\\n')\n",
    "        f.write(\"Score sd \" + str(sdScore) + '\\n')\n",
    "        f.write(\"All Scores\" + str(scores) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average Loss \" + str(avgLoss) + '\\n')\n",
    "        f.write(\"Loss sd \" + str(sdLoss) + '\\n')\n",
    "        f.write(\"All losses\" + str(loss) + '\\n\\n')\n",
    "\n",
    "        f.write(\"Average F1Score \" + str(avgF1Score) + '\\n')\n",
    "        f.write(\"F1Score sd \" + str(sdF1Score) + '\\n')\n",
    "        f.write(\"All F1 Scores\" + str(f1scores) + '\\n\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runMultipleTimes(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runWindowAndMinCount(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = [remove_stopwords(sent)  for sent in dataset['review']]\n",
    "X = [simple_preprocess(sent, deacc=True) for sent in X]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['sentiment'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(X, min_count=1, size=300, window=10)\n",
    "model.train(X, total_examples=len(X), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = []\n",
    "for sent in X_train:\n",
    "    sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "    X_train_v.append(sent_vector)\n",
    "\n",
    "    \n",
    "X_test_v = []\n",
    "for sent in X_test:\n",
    "    sent_vector = np.mean([model.wv[word] for word in sent if word in model.wv], axis=0)\n",
    "    X_test_v.append(sent_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=300)\n",
    "mlp.fit(X_train_v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.score(X_test_v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = mlp.predict(X_test_v)\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "02b38c1e9d8457fc8a9166044201f23127e668c9d7c521fe59929b5819de802a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}